vect[c("foo", "bar")]
x
x[1:10]
x[is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[3,5,7]
x[c(3,5,7)]
x[40]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2,10)]
vect <- c(foo = 11,bar = 2, norf = NA)
vect
names()vect
names(vect)
c(11, 2, NA)
c(11, 2, NA)
vect2<-c(11, 2, NA)
names(vect2) <- c("foo", "bar", "norf")
identical()vect,vect2
identical(vect,vect2 )
vect["bar"]
vect[c("foo", "bar")]
my_vector<-c(1:20)
my_vector<-1:20
my_vector
dim(my_vector)
length(my_vector)
dim(my_vector) <- c(4, 5)
dim(my_vector)
attributes(my_vector)
my_vector
class(my_vector)
my_matrix<-my_vector
?matrix
my_matrix2<-matrix(1:20,4,5)
identical(my_matrix, my_matrix2)
patients<-c("Bill","Gina","Kelly","Sean")
cbind(patients,my_matrix)
my_data <- data.frame(patients, my_matrix)
my_data
class(my_data)
cnames<-c("patient", "age", "weight", "bp", "rating", "test")
colnames
colnames(my_data)<-cnames
my_data
TRUE == TRUE
(FALSE == TRUE) == FALSE)
(FALSE == TRUE) == FALSE
6==7
6<7
10<=10
5!=7
5=7
5==7
!5==7
FALSE & FALSE
TRUE & c(TRUE, FALSE, FALSE)
TRUE && c(TRUE, FALSE, FALSE)
TRUE | c(TRUE, FALSE, FALSE)
TRUE || c(TRUE, FALSE, FALSE)
5 > 8 || 6 != 8 && 4 > 3.9
isTRUE(6 > 4)
identical('twins', 'twins')
xor(5== 6, !FALSE)
ints <- sample(10)
ints
ints > 5
which(ints>7)
any()
any(ints < 0)
all(ints < 0)
all(ints > 0)
head(flags)
dim(flags)
class(flags)
cls_list <- lapply(flags, class)
cls_list
class(cls_list)
as.character(cls_list)
?sapply
sapply(flags, class)
cls_vect <- sapply(flags, class)
class(cls_vect)
sum(flags$orange)
flag_colors <- flags[, 11:17]
head(flag_colors)
lapply(sum(flag_colors), )
lapply(sum(flag_colors), FUN )
lapply(sum(flag_colors), FUN )
head(flag_colors)
lapply(flag_colors, sum)
sapply(flag_colors, sum)
sapply(flag_colors, mean)
flag_shapes <- flags[, 19:23]
sapply(flag_shapes, mean)
lapply(flag_shapes, range)
shape_mat<-lapply(flag_shapes, range)
shape_mat <- sapply(flag_shapes, range)
shape_mat
class(shape_mat)
unique(c(3, 4, 5, 5, 5, 6,6)
unique(c(3, 4, 5, 5, 5, 6,6))
unique_vals<- unique(c(3, 4, 5, 5, 5, 6,6))
unique_vals <- lapply(flags, unique)
unique_vals
length(unique_vals)
sapply(unique_vals,length)
sapply(unique_vals,unique)
sapply(flags,unique)
lapply(unique_vals, function(elem) elem[2])
sapply(flags,unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
summary((flags$population)
summary(flags$population)
tapply(flags$population, flags$landmass, summary)
ls()
class(plants)
dim(plants)
nrows(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants)
head(plants,10)
tail(plants)
tail(plants,15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?sample
sample(1:6, 4, replace = TRUE)
(1/6)^4 = 0.00077
sample((1/6)^4 = 0.00077, replace = TRUE)
sample(1:6, 4, replace = TRUE)
sample(1:20,10,replace=FALSE)
sample(1:20,10)
LETTERS
sample(LETTERS)
sample(c(0,1), 100,prob = c(0.3, 0.7))
sample(100, c(0,1),prob = c(0.3, 0.7))
sample.int(100, c(0,1),prob = c(0.3, 0.7))
sample(LETTERS)
flips <- sample(c(0,1), 100, replace = TRUE, prob = c(0.3, 0.7))
flips
sum(flips)
?rbinom
rbinom(1, size = 100, prob = 0.7)
flips2<-rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(1, size = 100, prob = 0.7)
flips2 <- rbinom(size=1, n = 100, prob = 0.7)
flips2
head(flips2)
sum(flips2==TRUE)
sum(flips2)
?rnorm
rnorm(10)
rnorm(10,mean=100)
rnorm(10,mean=100,sd=25)
rpois(5,mean=10)
rpois(5,10)
replicat(100,rpois(5,10))
replicate(100,rpois(5,10))
my_pois<-replicate(100,rpois(5,10))
my_pois
cm<-colMeans(replicate(100,rpois(5,10)))
cm <- colMeans(my_pois)
hist(cm)
d1<-Sys.Date()
class(d1)
unclass(d1)
d1
d2<-as.Date("1969-01-01")
unclass(d2)
Sys.time
Sys.time()
t1<-Sys.time()
t1
class(t1)
unclass(t1)
t2<-as.POSIXlt(Sys.time())
t2
class(t2)
t
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(d1)
months(t1)
quarters(t2)
t3<-"October 17, 1986 08:24"
strptime
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
install_from_swirl("R Programming Alt")
swirl()
swirl()
q()
cube <- function(x, n) {
x^3
}
cube(3)
x <- 1:10
if(x > 5) {
x <- 0
}
if(x > 5) {
x <- 0
}
f <- function(x) {
g <- function(y) {
y + z
}
z <- 4
x + g(x)
}
z <- 10
f(3)
x <- 5
y <- if(x < 3) {
NA
} else {
10
}
q()
library(datasets)
data(iris)
?iris
str(iris)
mean(iris.Sepal.Lenght)
mean(iris$Sepal.Lenght)
6.588
apply(iris[, 1:4], 2, mean)
str(iris)
View(iris)
virginica <- subset(iris, Species == "virginica")
virginica
summary(virginica)
mean(iris[iris$Species == "virginica","Sepal.Length"])
data(mtcars)
str(mtcars)
(hp <- sapply(split(mtcars$hp, mtcars$cyl), mean))
hp[3]-hp[1]
x <- with(mtcars, tapply(hp, cyl, mean))
x
x[3] - x[1]
set.seed(1)
rpois(5, 2)
set.seed(10)
x <- rep(0:1, each = 5)
e <- rnorm(10, 0, 20)
y <- 0.5 + 2 * x + e
y
q()
Load the nc data set into our workspace.
load(url("http://bit.ly/dasi_nc"))
head(nc)
summary(nc)
gained_clean <- na.omit(nc$gained)
n <- length(gained_clean)
gained_clean <- na.omit(nc$gained)
n <- length(gained_clean)
## Exercise: Quick check: Double check that n is what it’s expected to be based
## on the number of NAs present in the original weight gain variable.
n == (1000-27)
boot_means <- rep(NA, 100)
for(i in 1:100){
boot_sample <- sample(gained_clean, n, replace = TRUE)
boot_means[i] <- mean(boot_sample)
}
hist(boot_means, breaks = 100)
s <- sd(gained_clean)
m <- mean(gained_clean)
n <- length(gained_clean)
SE <- s / sqrt(n)
Z <- abs(qnorm(0.05))
m + c(-1, 1) * Z * SE
s <- sd(boot_means)
m <- mean(boot_means)
m + c(-1, 1) * Z * s
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.9,
est = "mean", boot_method = "perc")
# We can easily change the confidence level to 95% by changing the conflevel:
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95,
est = "mean", boot_method = "perc")
# We can easily use the standard error method by changing the boot method:
inference(nc$gained, type = "ci", method = "simulation", conflevel = 0.95,
est = "mean", boot_method = "se")
q()
download.file(url = "http://bit.ly/dasi_project_template", destfile = "dasi_project_template.Rmd")
ls()
ls()
q()
makeCacheMatrix <- function(mtx = matrix()) {
inverse <- NULL
set <- function(x) {
mtx <<- x;
inverse <<- NULL;
}
get <- function() return(mtx);
setinv <- function(inv) inverse <<- inv;
getinv <- function() return(inverse);
return(list(set = set, get = get, setinv = setinv, getinv = getinv))
}
ls()
makeCacheMatrix <- function(mtx = matrix()) {
inverse <- NULL
set <- function(x) {
mtx <<- x;
inverse <<- NULL;
}
get <- function() return(mtx);
setinv <- function(inv) inverse <<- inv;
getinv <- function() return(inverse);
return(list(set = set, get = get, setinv = setinv, getinv = getinv))
}
makeVector <- function(x = numeric()) {
m <- NULL
set <- function(y) {
x <<- y
m <<- NULL
}
get <- function() x
setmean <- function(mean) m <<- mean
getmean <- function() m
list(set = set, get = get,
setmean = setmean,
getmean = getmean)
}
cachemean <- function(x, ...) {
m <- x$getmean()
if(!is.null(m)) {
message("getting cached data")
return(m)
}
data <- x$get()
m <- mean(data, ...)
x$setmean(m)
m
}
makeCacheMatrix <- function(mtx = matrix()) {
inverse <- NULL
set <- function(x) {
mtx <<- x;
inverse <<- NULL;
}
get <- function() return(mtx);
setinv <- function(inv) inverse <<- inv;
getinv <- function() return(inverse);
return(list(set = set, get = get, setinv = setinv, getinv = getinv))
}
## This function computes the inverse of the special
## "matrix" returned by `makeCacheMatrix` above. If the inverse has
## already been calculated (and the matrix has not changed), then
## `cacheSolve` should retrieve the inverse from the cache.
cacheSolve <- function(mtx, ...) {
inverse <- mtx$getinv()
if(!is.null(inverse)) {
message("Getting cached data...")
return(inverse)
}
data <- mtx$get()
invserse <- solve(data, ...)
mtx$setinv(inverse)
return(inverse)
}
inverse
makeVector(1)
cachemean(m)
1
cachemean(m)
makeVector(1)
cachemean(aa)
aa
aa<-makeVector(1)
aa
cachemean(aa)
makeCacheMatrix(aa)
cacheSolve(aa)
cacheSolve()
cacheSolve(makeCacheMatrix(1))
cacheSolve(makeCacheMatrix())
cacheSolve(makeCacheMatrix(1,2,3,4,5))
cacheSolve(makeCacheMatrix(1))
cacheSolve(makeCacheMatrix(13))
makeCacheMatrix()
cacheSolve()
makeCacheMatrix <- function(mtx = matrix()) {
inverse <- NULL
set <- function(x) {
mtx <<- x;
inverse <<- NULL;
}
get <- function() return(mtx);
setinv <- function(inv) inverse <<- inv;
getinv <- function() return(inverse);
return(list(set = set, get = get, setinv = setinv, getinv = getinv))
}
## This function computes the inverse of the special
## "matrix" returned by `makeCacheMatrix` above. If the inverse has
## already been calculated (and the matrix has not changed), then
## `cacheSolve` should retrieve the inverse from the cache.
cacheSolve <- function(mtx, ...) {
inverse <- mtx$getinv()
if(!is.null(inverse)) {
message("Getting cached data...")
return(inverse)
}
data <- mtx$get()
invserse <- solve(data, ...)
mtx$setinv(inverse)
return(inverse)
}
makeCacheMatrix()
cacheSolve()
View(makeCacheMatrix)
mtx<- makeCacheMatrix()
cacheSolve(mtx)
makeCacheMatrix <- function(x = matrix()) {
m_inv <- NULL
set <- function(y){
x <<- y
m_inv <<- NULL
}
get <- function() x
setInv <- function(inverse) m_inv <<- inverse
getInv <- function() m_inv
list(set = set, get = get, setInv = setInv, getInv = getInv)
}
##The function 'cacheSolve' computes the inverse of the matrix creted in the above function.
##If the inverse is already calculated, it retrives the inverse from the cache.
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x' if it is cached
m_inv <- x$getInv()
if (!is.null(m_inv)){
message("getting cached data...")
return(m_inv)
}
## Return a matric that is the inverse of 'x' if it is not cached
m_inv <- solve(x$get())
x$setInv(m_inv)
m_inv
}
makeCacheMatrix()
cacheSolve()
aa<-makeCacheMatrix()
cacheSolve(aa)
aa
setwd("./Duke/")
str(dt)
dt2<-gss[,c("coninc","race")]
dt <- subset(dt2, race != "NA")
dt <- subset(dt, coninc != "NA")
str(dt)
summary(dt$race)
length(levels(dt$race))
eda1<-summary(dt$race)
pie(eda1, labels = paste(levels(dt$race), " - ", round(eda1/sum(eda1)*100, digit = 1), " %", sep=""),col = rainbow(length(levels(dt$race))), main="Race Distribution in %")
library(ggplot2)
ggplot(dt, aes(x=coninc)) +
geom_histogram(binwidth=5000, colour="black", fill="blue") +
xlab("Income") +
ggtitle("Distribution of Family Income")
ggplot(dt, aes(x=race, y=coninc, fill=race)) +
geom_violin(alpha=0.2) +
xlab("Political Views") +
ylab("Income") +
ggtitle("Family Income vs Political Views")
ggplot(dt, aes(x=race, y=coninc, fill=qqq)) +
geom_violin(alpha=0.2) +
xlab("Political Views") +
ylab("Income") +
ggtitle("Family Income vs Political Views")
ggplot(dt, aes(x=race, y=coninc, fill=race)) +
geom_violin(alpha=0.2) +
xlab("Political Views") +
ylab("Income") +
ggtitle("Family Income vs Political Views")
ggplot(dt, aes(x=race, y=coninc, fill=race)) +
geom_violin(alpha=0.2) +
xlab("Race") +
ylab("Income") +
ggtitle("Family Income vs Race")
g <- ggplot(dt, aes(coninc, fill = race))
g + geom_density (alpha = 0.2) + labs(title = "Income distributions across Political Views levels") + labs(x = "Total Family Income", y = "Density")
g <- ggplot(dt, aes(coninc, fill = race))
g + geom_density (alpha = 0.5) + labs(title = "Income distributions across Races") + labs(x = "Total Family Income", y = "Density")
g <- ggplot(dt, aes(coninc, fill = race))
g + geom_density (alpha = 0.3) + labs(title = "Income distributions across Races") + labs(x = "Total Family Income", y = "Density")
inference(dt$race, est = "mean", type = "ht", method = "theoretical", null = 0,
alternative = "twosided")
